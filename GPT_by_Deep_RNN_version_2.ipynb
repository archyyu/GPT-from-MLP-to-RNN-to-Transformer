{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/GPT-from-MLP-to-RNN-to-Transformer/blob/main/GPT_by_Deep_RNN_version_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOcLhTikoHXs",
        "outputId": "13310bce-c3ff-4efc-b4f0-c1053c484497"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ec0402a4390>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pc3iAgLoLPl",
        "outputId": "2839a611-de5c-48c4-87db-219cd49f2e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 1115394 characters, 65 unique.\n"
          ]
        }
      ],
      "source": [
        "# Data I/O\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "#url = \"https://raw.githubusercontent.com/archyyu/publicResource/main/google.dev.en\"\n",
        "#url = \"https://raw.githubusercontent.com/torvalds/linux/master/mm/madvise.c\"\n",
        "response = requests.get(url)\n",
        "data = response.text\n",
        "\n",
        "n = int(0.9*len(data))\n",
        "training_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "chars = list(set(data))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print(f'data has {data_size} characters, {vocab_size} unique.')\n",
        "\n",
        "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
        "ix_to_char = {i: ch for i, ch in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F1bdC1IQoO7B"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 100\n",
        "embedding_dim = 40\n",
        "seq_length = 30\n",
        "learning_rate = 1e-1\n",
        "batch_size = 20\n",
        "deep_num = 3\n",
        "dropout_prob = 0.1\n",
        "eval_iters = 200\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vYsQApRTrXb"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVOCI3UDUT48"
      },
      "source": [
        "as illustrated by the above graph.\n",
        "we could define the layers of the rnn as deep_num\n",
        "and every hidden state is decided by the pre step hidden state and the lower layers hidden state.\n",
        "\n",
        "let us implement this structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqLiK6A3V_hY"
      },
      "source": [
        "from what I understand, If the RNN is deep, let say 3 layers, then the performance of the model should be better?\n",
        "\n",
        "but the result is a little disappointing. dont know why\n",
        "\n",
        "So I update the deepRNN again.\n",
        "\n",
        "Let see the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nIoS_FgoXQZ"
      },
      "outputs": [],
      "source": [
        "# We should change the VanillaRNN a little bit, so could be used in deep RNN.\n",
        "class SimpleRNN(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(SimpleRNN, self).__init__()\n",
        "    self.i2h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "    self.h2h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "    self.ob = nn.Parameter(torch.zeros(1, hidden_size))\n",
        "    # self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "  def forward(self, pre_h_list):\n",
        "    h_list = []\n",
        "    for i in range(pre_h_list.size(1)):\n",
        "      if i == 0:\n",
        "        h = torch.tanh(self.i2h(pre_h_list[:, i, :]) + self.ob)\n",
        "      else:\n",
        "        h = torch.tanh(self.i2h(pre_h_list[:, i, :]) + self.h2h(h) + self.ob)\n",
        "      h_list.append(h)\n",
        "\n",
        "    return torch.stack(h_list, dim=1)\n",
        "\n",
        "\n",
        "class DeepRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size, deep_num):\n",
        "    super(DeepRNN, self).__init__()\n",
        "    self.deep_num = deep_num\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.e2h = nn.Linear(embedding_dim, hidden_size, bias=False)\n",
        "    self.rnn_list = nn.ModuleList([SimpleRNN(hidden_size) for _ in range(deep_num)])\n",
        "    self.h2o = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "    self.ob = nn.Parameter(torch.zeros(1, vocab_size))\n",
        "\n",
        "  def forward(self, x, targets):\n",
        "    x = self.embedding(x)\n",
        "    B,T,C = x.shape\n",
        "    h = self.e2h(x)\n",
        "    for i in range(self.deep_num):\n",
        "      h = self.rnn_list[i](h)\n",
        "    y = self.h2o(h) + self.ob\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B,T = targets.shape\n",
        "      loss = F.cross_entropy(y.view(B*T, -1), targets.view(B*T))\n",
        "    return y, loss\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Model initialization\n",
        "model = DeepRNN(vocab_size, embedding_dim, hidden_size, deep_num)\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the above DeepRNN is writen from scrach\n",
        "the following DeepRNN is using pytorch.rnn\n",
        "let us compare those two models, to see which is better."
      ],
      "metadata": {
        "id": "jNSfbTnRDSmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepRnn(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size, deep_num):\n",
        "    super(DeepRnn, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.deep_num = deep_num\n",
        "    self.deep_rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size, num_layers=deep_num, batch_first=True)\n",
        "    self.h2o = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, x, targets):\n",
        "    x = self.embedding(x)\n",
        "    B,T,C = x.shape\n",
        "    hidden_state = torch.zeros(self.deep_num, B, hidden_size)\n",
        "    y, hidden_state = self.deep_rnn(x, hidden_state)\n",
        "    y = self.h2o(y)\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      loss = F.cross_entropy(y.reshape(B*T, -1), targets.view(B*T))\n",
        "    return y, loss\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Model initialization\n",
        "model = DeepRnn(vocab_size, embedding_dim, hidden_size, deep_num)\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Fo2dEYHa_br6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4XAnPXWhZ8z"
      },
      "source": [
        "I updated the VanillaRNN a little, since We dont need the output of the intermediate node in Deep RNN, so we could remove the self.h2o linear layer. and add an final linear layer in the upper layer, by doing so, we could significantly reduce the amount of the parameters in the nn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PgvNUMTTzp72"
      },
      "outputs": [],
      "source": [
        "def get_batch(split):\n",
        "  batch_inputs = []\n",
        "  batch_targets = []\n",
        "\n",
        "  data = training_data\n",
        "  if split == \"val\":\n",
        "    data = val_data\n",
        "\n",
        "  start_idx = torch.randint(len(data) - batch_size - seq_length - 2,[1]).item()\n",
        "  for i in range(batch_size):\n",
        "    p = start_idx + i\n",
        "    inputs = torch.tensor([char_to_ix[ch] for ch in data[p:p + seq_length]], dtype=torch.long).view(1, -1)\n",
        "    targets = torch.tensor([char_to_ix[ch] for ch in data[p + 1:p + seq_length + 1]], dtype=torch.long).view(-1)\n",
        "\n",
        "    batch_inputs.append(inputs)\n",
        "    batch_targets.append(targets)\n",
        "\n",
        "  # Convert lists to tensors\n",
        "  minibatch_inputs = torch.cat(batch_inputs, dim=0)\n",
        "  minibatch_targets = torch.stack(batch_targets)\n",
        "  return minibatch_inputs, minibatch_targets\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "t7miViwQnRUd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ae3a47-ec44-4d6d-d679-c455acd74c92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 1.9753, val loss 2.0653\n",
            "step 1000: train loss 1.9504, val loss 2.0511\n",
            "step 2000: train loss 1.9305, val loss 2.0315\n",
            "step 3000: train loss 1.9052, val loss 1.9991\n",
            "step 4000: train loss 1.9313, val loss 2.0132\n",
            "step 5000: train loss 1.9188, val loss 1.9987\n",
            "step 6000: train loss 1.8957, val loss 1.9998\n",
            "step 7000: train loss 1.8525, val loss 1.9648\n",
            "step 8000: train loss 1.8692, val loss 1.9443\n",
            "step 9000: train loss 1.8563, val loss 1.9670\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_iterations = 10000\n",
        "for iteration in range(num_iterations):\n",
        "\n",
        "  inputs, targets = get_batch('train')\n",
        "\n",
        "  predict_char, loss = model(inputs, targets)\n",
        "\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  B,T = targets.shape\n",
        "\n",
        "  loss = criterion(predict_char.reshape(B*T, -1), targets.view(B*T))\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  for param in model.parameters():\n",
        "    if param.grad is not None:\n",
        "      param.grad.data.clamp_(-5, 5)\n",
        "\n",
        "  optimizer.step()\n",
        "  if iteration % 1000 == 0:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"step {iteration}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9FANLvcoQtW",
        "outputId": "b54d79ea-81c1-415e-bb17-209cacbc9dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FIBLA:\n",
            "Is mnaentreming, eare, that vile she netdould brot.\n",
            "I stong, much hear comnowy then never rest from the decier,\n",
            "Of suind, thou a pardom for the, list mun suustity, why, did, to you heart that licd.\n",
            "Mo you by struid we quleon,\n",
            "And my lord-home is never, boorsrand heavancem\n",
            "An clace,\n",
            "Sid deak your cise is hofs.\n",
            "\n",
            "COPELLA:\n",
            "Honbentects he stale a prist.,\n",
            "I'll heart.\n",
            "\n",
            "FORIOLANUS:\n",
            "Poot ondon do;\n",
            "And I have is the all mone you, I bry, your vow out ce were in the rocer be crint'd his quetloters,\n",
            "And and call with plear int, we now\n",
            "So yoo st, that sees,\n",
            "How doth his have lover my your give hell behited if;\n",
            "Mom,\n",
            "Whmawer: on hone so. goods'd the doth'ate, and with hoffe! sucence, on day you have combbems, I you what cous, no breein, sill batelcisitrand?\n",
            "Weter: my An my lovers with there the desishly to fort a tbough no do shall out\n",
            "The in a play,\n",
            "I spead the prone had for inturetaek both and carth, and it that and none, baey, my\n",
            "Acroung-sent,\n",
            "And my hone.\n",
            "\n",
            "Sherates been a cosfer pur, denting\n",
            "As cit,\n",
            "Cove, butnot.\n",
            "\n",
            "MONRY VI:\n",
            "Ruse your ckence, them got tig, bught I sraen? whorst helpust thou zoughvemer meling\n",
            "to boo, deann, anglobleds bear, the been\n",
            "shall nabu,\n",
            "Heefouse\n",
            "Hath in for can, The oe us, your was\n",
            "whings: didly use you tol, Orow,\n",
            "I day shing knows Engly an his rent tood groust,\n",
            "Tha!\n",
            "It it the, if I conten, ganget fordly covarous\n",
            "To by his dind fray fagnors, or a vope anbace. with epent thisfeled fairs of ipt the pouse;\n",
            "Co, werhiss upneds.\n",
            "Whost.\n",
            "Pone fone,\n",
            "And good, liver them, my not there,\n",
            "And\n",
            "thich grome of this there desten sweak hime.\n",
            "Coms\n",
            "thich to extuch one resire\n",
            "Hath sixps, we the hoods,\n",
            "Sear torrow in laher the dewwy, and thou mear is that it as stolm right:\n",
            "\n",
            "TRENTY LARI VINCESE:\n",
            "Nid, and\n",
            "Hedes to and a pot and all Mrace, do use were every, to your shall now righidhrow.\n",
            "\n",
            "SICINIUS:\n",
            "Whosmune,\n",
            "Sight, the him ride the bonnby, the much\n",
            "I Larch have hid blow Gisfed: Then blood uncing for Gill butt.\n",
            "Ad thy hissered.\n",
            "\n",
            "PUMBENA:\n",
            "O fhis\n",
            "the ray will you will you ary\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  # Sample from the model\n",
        "  x = torch.tensor(char_to_ix[data[0]], dtype=torch.long).view(1, 1)\n",
        "  ixes = []\n",
        "  ixes.append(ix_to_char[x[0][0].item()])\n",
        "\n",
        "  n = 2000\n",
        "\n",
        "  for _ in range(n):\n",
        "    inputs = torch.tensor([char_to_ix[ch] for ch in ixes[-seq_length * 2:]], dtype=torch.long).view(1, -1)\n",
        "    outputs,_ = model(inputs, None)\n",
        "    outputs = outputs[:,-1,:]\n",
        "    p = nn.functional.softmax(outputs, dim=-1).detach().numpy().ravel()\n",
        "    ix = np.random.choice(range(vocab_size), p=p)\n",
        "    y = torch.tensor(ix, dtype=torch.long).view(1, 1)\n",
        "\n",
        "    ixes.append(ix_to_char[y[0][0].item()])\n",
        "\n",
        "  print(''.join(ixes))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the new version, I made it more deep(3 layers) and also added the evaluation machenism to varify the model to prevent it from overfitting.\n",
        "\n",
        "I like the idea of deep rnn."
      ],
      "metadata": {
        "id": "9Wi_7CchbCW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "overall the performacne of the deep rnn is not good\n",
        "maybe we could try the deep rnn provided by pytorch\n",
        "let us do that"
      ],
      "metadata": {
        "id": "qygWn1hd_Lr3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aFAFc5Ld_UXJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVdPu8Myg+y6NQvO9319yk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}