{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhMRpJFiYdlzPLIGnZimon",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/RNN-GPT/blob/main/studyRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "uOcLhTikoHXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b953b6-4e88-4c7e-bfb0-fb13bc0d2234"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b15c0030310>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data I/O\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "#url = \"https://raw.githubusercontent.com/archyyu/publicResource/main/google.dev.en\"\n",
        "#url = \"https://raw.githubusercontent.com/torvalds/linux/master/mm/madvise.c\"\n",
        "response = requests.get(url)\n",
        "data = response.text\n",
        "\n",
        "chars = list(set(data))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print(f'data has {data_size} characters, {vocab_size} unique.')\n",
        "\n",
        "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
        "ix_to_char = {i: ch for i, ch in enumerate(chars)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pc3iAgLoLPl",
        "outputId": "e255d869-01ef-4096-ef89-2f0d7aeb12c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 1115394 characters, 65 unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 100\n",
        "embedding_dim = 20\n",
        "seq_length = 25\n",
        "learning_rate = 1e-1\n",
        "batch_size = 20"
      ],
      "metadata": {
        "id": "F1bdC1IQoO7B"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "class VanillaRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "    super(VanillaRNN, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.i2h = nn.Linear(embedding_dim, hidden_size)\n",
        "    self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "    self.h2o = nn.Linear(hidden_size, vocab_size)\n",
        "    self.hb2 = nn.Parameter(torch.zeros(1, hidden_size))\n",
        "    self.ob = nn.Parameter(torch.zeros(1, vocab_size))\n",
        "\n",
        "  def forward(self, x, h):\n",
        "    x = self.embedding(x)\n",
        "    h2 = torch.tanh(self.i2h(x) + self.h2h(h) + self.hb2)\n",
        "    y = self.h2o(h2) + self.ob\n",
        "    return y, h2\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Model initialization\n",
        "model = VanillaRNN(vocab_size, embedding_dim, hidden_size)\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "2nIoS_FgoXQZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateMiniBatch(start_idx):\n",
        "  batch_inputs = []\n",
        "  batch_targets = []\n",
        "\n",
        "  # Generate examples for the current minibatch\n",
        "  for i in range(batch_size):\n",
        "    p = start_idx + i\n",
        "    inputs = torch.tensor([char_to_ix[ch] for ch in data[p:p + seq_length]], dtype=torch.long).view(1, -1)\n",
        "    targets = torch.tensor([char_to_ix[ch] for ch in data[p + 1:p + seq_length + 1]], dtype=torch.long).view(-1)\n",
        "\n",
        "    batch_inputs.append(inputs)\n",
        "    batch_targets.append(targets)\n",
        "\n",
        "  # Convert lists to tensors\n",
        "  minibatch_inputs = torch.cat(batch_inputs, dim=0)\n",
        "  minibatch_targets = torch.cat(batch_targets, dim=0)\n",
        "  return minibatch_inputs, minibatch_targets"
      ],
      "metadata": {
        "id": "PgvNUMTTzp72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "t7miViwQnRUd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "outputId": "1d65a326-ba22-4f5c-b44d-b2ddc04bb8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 1.461213911473751\n",
            "Iteration 100, Loss: 2.388749783039093\n",
            "Iteration 200, Loss: 2.042467204928398\n",
            "Iteration 300, Loss: 1.8395315510034562\n",
            "Iteration 400, Loss: 2.506123238801956\n",
            "Iteration 500, Loss: 2.5262410606443884\n",
            "Iteration 600, Loss: 2.056482539176941\n",
            "Iteration 700, Loss: 2.1896510237455367\n",
            "Iteration 800, Loss: 1.650094143152237\n",
            "Iteration 900, Loss: 2.5060903424024583\n",
            "Iteration 1000, Loss: 1.9856063830852508\n",
            "Iteration 1100, Loss: 2.5597991037368772\n",
            "Iteration 1200, Loss: 2.6833739322423935\n",
            "Iteration 1300, Loss: 2.1536571943759917\n",
            "Iteration 1400, Loss: 2.217836757898331\n",
            "Iteration 1500, Loss: 2.6447662043571474\n",
            "Iteration 1600, Loss: 2.0042198586463926\n",
            "Iteration 1700, Loss: 2.096113713979721\n",
            "Iteration 1800, Loss: 2.189876298904419\n",
            "Iteration 1900, Loss: 1.9852752423286437\n",
            "Iteration 2000, Loss: 2.1876582396030426\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b229e97f2533>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0moutput_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mpredict_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtotalloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-8da75b38fdcf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi2h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_iterations = 10000\n",
        "p = 0\n",
        "for iteration in range(num_iterations):\n",
        "\n",
        "  if p + seq_length + 1 > len(data):\n",
        "    p = 0;\n",
        "\n",
        "  inputs = torch.tensor([char_to_ix[ch] for ch in data[p:p + seq_length]], dtype=torch.long).view(1, -1)\n",
        "  targets = torch.tensor([char_to_ix[ch] for ch in data[p + 1:p + seq_length + 1]], dtype=torch.long).view(-1)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  totalloss = 0\n",
        "  hprev = torch.zeros(1, hidden_size)  # Reset RNN memory\n",
        "  for i in range(seq_length):\n",
        "    input_char = (inputs[0][i]).view(1, -1)\n",
        "    output_char = targets[i]\n",
        "\n",
        "    predict_char, hprev = model(input_char, hprev)\n",
        "    loss = criterion(predict_char[0][0], output_char)\n",
        "    totalloss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    hprev = hprev.detach()\n",
        "\n",
        "    for param in model.parameters():\n",
        "      if param.grad is not None:\n",
        "        param.grad.data.clamp_(-5, 5)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  if iteration % 100 == 0:\n",
        "    print(f'Iteration {iteration}, Loss: {totalloss/seq_length}')\n",
        "\n",
        "  p += seq_length  # Move data pointer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample from the model\n",
        "def sample(model, seed_ix, n):\n",
        "  h = torch.zeros(1, hidden_size)\n",
        "  x = torch.tensor(seed_ix, dtype=torch.long).view(1, 1)\n",
        "  ixes = []\n",
        "\n",
        "  for _ in range(n):\n",
        "    outputs, h = model(x, h)\n",
        "    p = nn.functional.softmax(outputs, dim=-1).detach().numpy().ravel()\n",
        "    ix = np.random.choice(range(vocab_size), p=p)\n",
        "    x = torch.tensor(ix, dtype=torch.long).view(1, 1)\n",
        "    ixes.append(ix)\n",
        "\n",
        "  return ixes"
      ],
      "metadata": {
        "id": "I9FANLvcoQtW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sample text\n",
        "sample_ix = sample(model, char_to_ix[data[0]], 2000)\n",
        "txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
        "print(f'Generated Text:\\n{txt}')"
      ],
      "metadata": {
        "id": "gIyG1ucAoVJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ddad80-89f6-4d4a-f269-ef521813b2be"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "y hourever of in.\n",
            "\n",
            "BUCKBETor win yous heaud oean id this lor, yeand\n",
            "Hukn:\n",
            "BUCESTERISZSTEFomr lelinendiine;\n",
            "As to ciay,\n",
            "Bernow yiind'uror Ehye wh cecanlye;\n",
            "Buk'dsedrotid in hiene bu yaitty seinend lend;\n",
            "Lot, nof\n",
            "An Sataudore Hatnoortizll aur fatiid of yies;\n",
            "Whe nes sheinyo ind maru give his lofbere of ness ofr is L'n bull it irth wien:\n",
            "TIM:\n",
            "Weveather hastind tifey; the\n",
            "Lecweve rind; an ther ther of mint noowessofMeur figd's sou dor farau It hir fon hy your I co wirara hicis of prand?\n",
            "Hoe insorder opard sou Bu cower sudes feay opid rei,\n",
            "Bang, bill'de thicher four fold Hom far the bins migind boness notforl,\n",
            "\n",
            "BUCKINUNGHo wings off's oursy win oeay no,\n",
            "Where of\n",
            "AyAnd des otes coure herd the snty mard;\n",
            "\n",
            "Bn Eotink diny gind;\n",
            "Selfatenty,\n",
            "\n",
            "Bigt in acqind ul hinge novil ond\n",
            "Hord yimme,\n",
            "\n",
            "GAM:\n",
            "Ms dcoed curp,\n",
            "And in I father fajy woritize bous toucer prind;\n",
            "Uoin; Iist,\n",
            "Aeche lige lon yenfor; you tFrief th meve bemend;\n",
            "\n",
            "Hing of or, of the rikr yececeng,her pot\n",
            "Werey thien:\n",
            "\n",
            "BS Eother fot whe wece.\n",
            "of ness noblar, in the the spere Hek h?\n",
            "An nor to bhe nen bord by Larld in yiave gay otherlint well your dothen harend deke nowe fo'd ford fo mayv\n",
            "Tis to fy nothon lotin the cam iss thall fay nof decth, in yoth'ct sitizer ded engivin\n",
            "OUCKS the thice, of teraind ho ind vind,\n",
            "\n",
            "Kfishad Lnr:\n",
            "That lorden's vitizein cind an wous whem theror:\n",
            "HOUCES your cit in your cou thicer nof Shie udliced ind;\n",
            "Asds\n",
            "BIen acline meiis novd your upillis oues,\n",
            "As ofd soriord verenig nosous notfor,\n",
            "Friaices your of san izesus wis fend;\n",
            "\n",
            "HACES\n",
            "Andou fell ther of you fein of ANGINGHAM:\n",
            "Hhour you thery;\n",
            "Theis buream thed otlay, nonsireadkimen co cithe you, four igdstwams pidy fan your opour the your jhard Horims sildendour an your and her our milhor Bu rits dou I wikt of youche lenranded and bord fith, hou nould indour cur yother:;Ber Easet bit mes.\n",
            "Ard I hard des;oor ys lived her ipe,\n",
            "Ned ser yor biego of ar I Llds Sor ar Yus,\n",
            "I your par no live bour of din,\n",
            "Bis may jigper the sers;\n",
            "Whirto-\n",
            "Be Yut'y this may\n",
            "\n",
            "B\n"
          ]
        }
      ]
    }
  ]
}