{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCw6o7w5lpssKJu0Nipweh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/GPT-from-MLP-to-RNN-to-Transformer/blob/main/GPT_by_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT6RmPTME296",
        "outputId": "3036b88b-7f8e-447d-ec99-2bdacbf20f5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c7931d6c410>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data I/O\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "#url = \"https://raw.githubusercontent.com/archyyu/publicResource/main/google.dev.en\"\n",
        "#url = \"https://raw.githubusercontent.com/tinygrad/tinygrad/master/tinygrad/tensor.py\"\n",
        "#url = \"https://raw.githubusercontent.com/archyyu/publicResource/main/KDE4.en-es.en\"\n",
        "#url = \"https://raw.githubusercontent.com/archyyu/publicResource/main/js\"\n",
        "response = requests.get(url)\n",
        "data = response.text\n",
        "\n",
        "chars = list(set(data))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print(f'data has {data_size} characters, {vocab_size} unique.')\n",
        "\n",
        "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
        "ix_to_char = {i: ch for i, ch in enumerate(chars)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw0Mc-HCGHQ1",
        "outputId": "bba3db95-da08-4c97-84de-4d14666ef394"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 1115394 characters, 65 unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjfYPqs8N2ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_size = 128\n",
        "embedding_dim = 40\n",
        "seq_length = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 20"
      ],
      "metadata": {
        "id": "JUKwqcBGGJSL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, seq_length, vocab_size, embedding_dim, hidden_size):\n",
        "    super(MLP, self).__init__()\n",
        "    self.em = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.W1 = nn.Linear(seq_length * embedding_dim, hidden_size)\n",
        "    self.b1 = nn.Parameter(torch.zeros(1, hidden_size))\n",
        "\n",
        "    self.W2 = nn.Linear(hidden_size, vocab_size)\n",
        "    self.b2 = nn.Parameter(torch.zeros(1, vocab_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.em(x)\n",
        "    x = x.view(x.shape[0],-1)\n",
        "    h1 = torch.tanh(self.W1(x) + self.b1)\n",
        "    y = self.W2(h1) + self.b2\n",
        "    return y\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = MLP(seq_length, vocab_size, embedding_dim, hidden_size)\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "dQpTC3RZE75U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mini_batch():\n",
        "  # Assuming batch_size is a variable representing the desired batch size\n",
        "  # and data is your input sequence data\n",
        "\n",
        "  # Initialize lists to store input sequences and corresponding targets for the minibatch\n",
        "  batch_inputs = []\n",
        "  batch_targets = []\n",
        "\n",
        "  # Loop to generate the minibatch\n",
        "  for _ in range(batch_size):\n",
        "    # Randomly select a starting point for the sequence\n",
        "    p = np.random.randint(0, len(data) - seq_length - 1)\n",
        "\n",
        "    # Extract a sequence of characters and convert them to indices\n",
        "    inputs = torch.tensor([char_to_ix[ch] for ch in data[p:p + seq_length]], dtype=torch.long).view(1, -1)\n",
        "\n",
        "    # Extract the target character and convert it to an index\n",
        "    target = torch.tensor([char_to_ix[data[p + seq_length]]], dtype=torch.long).view(1, -1)\n",
        "\n",
        "    # Append the input sequence and target to the minibatch lists\n",
        "    batch_inputs.append(inputs)\n",
        "    batch_targets.append(target)\n",
        "\n",
        "  # Combine the lists into tensors to form the minibatch\n",
        "  minibatch_inputs = torch.cat(batch_inputs, dim=0)\n",
        "  minibatch_targets = torch.cat(batch_targets, dim=0)\n",
        "  return minibatch_inputs, minibatch_targets"
      ],
      "metadata": {
        "id": "X2oUPoQXh6XN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tinputs, ttargets = generate_mini_batch()\n",
        "print(tinputs.shape)\n",
        "em = nn.Embedding(vocab_size, embedding_dim)\n",
        "tinputs = em(tinputs)\n",
        "print(tinputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wNRlWgjj4Zl",
        "outputId": "747f0f40-11b7-4b8b-83a9-a9e605eea118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 10])\n",
            "torch.Size([20, 10, 40])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tinputs = tinputs.view(tinputs.shape[0], -1)\n",
        "print(tinputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t13L93g5lQ9F",
        "outputId": "f142c3d0-b4d5-4141-920a-c3f9f19e3af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "stopi = []\n",
        "lossi = []\n",
        "num_iterations = 5\n",
        "for iteration in range(num_iterations):\n",
        "\n",
        "  for p in range(len(data) - seq_length):\n",
        "\n",
        "    # inputs = torch.tensor([char_to_ix[ch] for ch in data[p:p + seq_length]], dtype=torch.long).view(1, -1)\n",
        "    # targets = torch.tensor([char_to_ix[ch] for ch in data[p + seq_length]], dtype=torch.long).view(-1)\n",
        "\n",
        "    inputs,targets = generate_mini_batch()\n",
        "\n",
        "    # inputs, targets = generateMiniBatch(p)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    predict_char = model(inputs)\n",
        "    loss = criterion(predict_char, targets.view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    for param in model.parameters():\n",
        "      if param.grad is not None:\n",
        "        param.grad.data.clamp_(-5, 5)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    if p % 2000 == 0:\n",
        "      print(f'Iteration {(iteration + 1) * p}, Loss: {loss.item()}')\n",
        "      stopi.append((iteration + 1) * p)\n",
        "      lossi.append(loss.item())\n",
        "\n"
      ],
      "metadata": {
        "id": "sLe4BKaHOuAZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca79165f-35b0-4b22-80b3-741362bab1f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 4.241756916046143\n",
            "Iteration 2000, Loss: 2.824963331222534\n",
            "Iteration 4000, Loss: 3.118701934814453\n",
            "Iteration 6000, Loss: 2.4798660278320312\n",
            "Iteration 8000, Loss: 2.841740608215332\n",
            "Iteration 10000, Loss: 2.8392560482025146\n",
            "Iteration 12000, Loss: 3.1624820232391357\n",
            "Iteration 14000, Loss: 2.6113734245300293\n",
            "Iteration 16000, Loss: 2.717923164367676\n",
            "Iteration 18000, Loss: 2.434124231338501\n",
            "Iteration 20000, Loss: 2.7914299964904785\n",
            "Iteration 22000, Loss: 2.915992498397827\n",
            "Iteration 24000, Loss: 3.1007049083709717\n",
            "Iteration 26000, Loss: 2.2684779167175293\n",
            "Iteration 28000, Loss: 2.6782078742980957\n",
            "Iteration 30000, Loss: 2.960998058319092\n",
            "Iteration 32000, Loss: 2.4407949447631836\n",
            "Iteration 34000, Loss: 2.174156665802002\n",
            "Iteration 36000, Loss: 2.0529162883758545\n",
            "Iteration 38000, Loss: 2.228592872619629\n",
            "Iteration 40000, Loss: 2.2606005668640137\n",
            "Iteration 42000, Loss: 2.3004398345947266\n",
            "Iteration 44000, Loss: 2.3880856037139893\n",
            "Iteration 46000, Loss: 2.3565449714660645\n",
            "Iteration 48000, Loss: 2.484656572341919\n",
            "Iteration 50000, Loss: 2.698873281478882\n",
            "Iteration 52000, Loss: 1.8200721740722656\n",
            "Iteration 54000, Loss: 2.2741305828094482\n",
            "Iteration 56000, Loss: 1.8718490600585938\n",
            "Iteration 58000, Loss: 2.135128974914551\n",
            "Iteration 60000, Loss: 2.800295352935791\n",
            "Iteration 62000, Loss: 2.479728937149048\n",
            "Iteration 64000, Loss: 3.0458576679229736\n",
            "Iteration 66000, Loss: 2.6980464458465576\n",
            "Iteration 68000, Loss: 2.487993001937866\n",
            "Iteration 70000, Loss: 2.4229958057403564\n",
            "Iteration 72000, Loss: 1.9322446584701538\n",
            "Iteration 74000, Loss: 2.70619535446167\n",
            "Iteration 76000, Loss: 1.9735348224639893\n",
            "Iteration 78000, Loss: 2.70462965965271\n",
            "Iteration 80000, Loss: 2.6898584365844727\n",
            "Iteration 82000, Loss: 1.878111481666565\n",
            "Iteration 84000, Loss: 2.4170093536376953\n",
            "Iteration 86000, Loss: 2.688631772994995\n",
            "Iteration 88000, Loss: 2.6263203620910645\n",
            "Iteration 90000, Loss: 2.508546829223633\n",
            "Iteration 92000, Loss: 1.8366422653198242\n",
            "Iteration 94000, Loss: 2.030897378921509\n",
            "Iteration 96000, Loss: 2.1086864471435547\n",
            "Iteration 98000, Loss: 2.7141823768615723\n",
            "Iteration 100000, Loss: 2.3483829498291016\n",
            "Iteration 102000, Loss: 1.9143108129501343\n",
            "Iteration 104000, Loss: 2.2227089405059814\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7aca7e791523>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mpredict_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-866fedfe78b5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = \"First Citizen\"\n",
        "\n",
        "for i in range(1000):\n",
        "  lll = start[-seq_length:]\n",
        "  ll = torch.tensor([char_to_ix[ch] for ch in lll], dtype=torch.long).view(1, -1)\n",
        "  outputs = model(ll)\n",
        "  p = nn.functional.softmax(outputs, dim=-1).detach().numpy().ravel()\n",
        "  ix = np.random.choice(range(vocab_size), p=p)\n",
        "  ix = torch.tensor(ix, dtype=torch.long).view(1, 1)\n",
        "  start += ix_to_char[ix[0][0].item()]\n",
        "\n",
        "print(start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngbcAiVDgSs_",
        "outputId": "36ae01a2-efbb-4a18-ea95-e9aa6c0e43e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n",
            "BFty,uos silh Pben bo dat as ind siat\n",
            ".ingit the kn the sear, hou sca.\n",
            "Vofe.l\n",
            "PUO\n",
            "VVEIE TIR Lhad yevr;owd de he haus piwithd wishan&amas in tmomlldt' roas to fimaor on and and thevolbat ond ak medt Cop boll, s Gme iak sir,eon -sare charltherang, dous ?elire,\n",
            "Inar Zelnnd- hon bins be th.\n",
            "\n",
            "Say soatt eanhe peds\n",
            "Hal e't le co\n",
            "NIOn\n",
            "TpOe hab low't afcat wedlle\n",
            "andthe erethet oard heas irs:\n",
            "Wapr Prndo san inkerthou, ale Fravsh'Tkeu oud ho?.\n",
            "\n",
            "IUCLO!DS:\n",
            "Nias op cRrranke th, 'e ilr wiln huee leate, noin;\n",
            "Fi' sur est thm's or'dls anent hau erdst of Aos ail secidno\n",
            "\n",
            ":uars pol!\n",
            "Ghhe Rhay,\n",
            "\n",
            "Shes gor'dp\n",
            "CRind he fotherseor the dithatnd Lutk ow tas Wery arvtreit sting,us end beeeives ceap's thrKinqatot whir ?e prowe thas and' sere hou torlyws, lMy nowe whee ledse the tergwe,\n",
            "Aof ken ogsot al wethe\n",
            "'sith whavk rfar.\n",
            "LAhony bI of sond the bondest che hace ise in my theiafer\n",
            "Whis ay the doo noat.\n",
            "Aur Chit gurdedv\n",
            "Shis fwompgeners ynd aflinbe fent sitgeves'gHior ldwe the there hi\n",
            "AfI Inomen bere ous\n",
            "Fent\n"
          ]
        }
      ]
    }
  ]
}